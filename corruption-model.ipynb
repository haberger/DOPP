{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "from data_cleanup import *\n",
    "from feature_selection import *\n",
    "from model_ import *\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from sklearn.metrics import mean_squared_error as rmse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cols = ['ti_cpi', 'bci_bci', 'ti_cpi_om', 'wbgi_cce']\n",
    "meta_cols = ['ccode', 'ccode_qog', 'ccodealp', 'ccodealp_year', 'ccodecow', 'cname', 'cname_qog', 'cname_year', 'version', 'year', 'region', 'sub-region']\n",
    "df = load_reduced_df(corr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_date_columns(df)\n",
    "\n",
    "best_features_dict = {}\n",
    "selected_features_dict = {}\n",
    "\n",
    "for target_col in corr_cols:\n",
    "    X_train, X_test, y_train, y_test = create_traintestsplit(df, corr_cols = corr_cols, meta_cols=meta_cols, target_col=target_col)\n",
    "    \n",
    "    best_features = pre_select(X_train, y_train)\n",
    "    best_features_dict[target_col] = set(best_features)\n",
    "    df_train = X_train[best_features].copy()\n",
    "    df_train[target_col]=y_train\n",
    "    mce = MultiCollinearityEliminator(df_train, target_col, 0.85)\n",
    "    feaures_no_collinearity = list(mce.autoEliminateMulticollinearity().columns)\n",
    "    feaures_no_collinearity.remove(target_col)\n",
    "    selected_features_dict[target_col] = set(feaures_no_collinearity)\n",
    "selected_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_union=list(set.union(*list(best_features_dict.values())))\n",
    "best_features_intersection=list(set.intersection(*list(best_features_dict.values())))\n",
    "\n",
    "best_features_intersection\n",
    "\n",
    "print(df[best_features_union].isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_union=list(set.union(*list(selected_features_dict.values())))\n",
    "selected_features_intersection=list(set.intersection(*list(selected_features_dict.values())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "To model the data we tried out a Lasso linear model and a random forest regressor. Based on our pre selection process we train our models on different feature configurations:\n",
    "\n",
    "    - the individual selected features for a particular index\n",
    "    - the intersection of all selected features for all indices\n",
    "    - the union of selected features for all indices\n",
    "    - the union of selected features for all indices without filtering based on collinearity\n",
    "\n",
    "To report the accuracy of the model we use r2 and the rmse as metrics.\n",
    "    \n",
    "### Lasso\n",
    "The used library uses cross validation to determine a good value for alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_info_script(features, name):\n",
    "    lasso_bf = dict()\n",
    "\n",
    "    df_score = pd.DataFrame(columns=['r2', 'rmse'], index=corr_cols)\n",
    "    for target in corr_cols:\n",
    "        if isinstance(features, dict):\n",
    "            lasso_bf[target] = apply_lassocv(df, target, list(features[target]), corr_cols, meta_cols, fprint=False)\n",
    "        else:\n",
    "            lasso_bf[target] = apply_lassocv(df, target, features, corr_cols, meta_cols, fprint=False)\n",
    "        df_score.loc[target,] = [lasso_bf[target]['r2'] ,lasso_bf[target]['rmse']]\n",
    "    \n",
    "    print('scores:' + name)\n",
    "    display(df_score)\n",
    "    \n",
    "lasso_info_script(selected_features_dict, ' Selected Features')\n",
    "lasso_info_script(selected_features_intersection, 'Features intersection')\n",
    "lasso_info_script(selected_features_union, 'selected Features union')\n",
    "lasso_info_script(best_features_union, ' selected Features union without collinearity filter')\n",
    "\n",
    "# print(len(best_features_union))\n",
    "# print(len(selected_features_intersection))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the models perform all very similar with a slight edge for the models with more features. This was to be expected, due to the fact, that the features where preselected. It can also be seen, that the the collinearity does not seem to pose a problem to the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Next we do the same for a Random Forest Regressor. Here initially no cross validation is done. We just use a default setup at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_info_script(features, name):\n",
    "    rf_bf = dict()\n",
    "\n",
    "    df_score = pd.DataFrame(columns=['r2', 'rmse'], index=corr_cols)\n",
    "    for target in corr_cols:\n",
    "        if isinstance(features, dict):\n",
    "            rf_bf[target] = apply_rf(df, target, list(features[target]), corr_cols, meta_cols, fprint=False)\n",
    "        else:\n",
    "            rf_bf[target] = apply_rf(df, target, features, corr_cols, meta_cols, fprint=False)\n",
    "        df_score.loc[target,] = [rf_bf[target]['r2'] ,rf_bf[target]['rmse']]\n",
    "    \n",
    "    print('scores:' + name)\n",
    "    display(df_score)\n",
    "\n",
    "rf_info_script(selected_features_dict, ' Selected Features')\n",
    "rf_info_script(selected_features_intersection, 'Features intersection')\n",
    "rf_info_script(selected_features_union, 'selected Features union')\n",
    "rf_info_script(best_features_union, ' selected Features union without collinearity filter')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest performs very  similarly to the lasso model allthough no parameter optimization is done by now. So we continue with Random Forst and do hyperparameter optimization for some specific settings next to further optimize the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search: Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cross validation / hyperparameter grid search better parameters are determined. With those optimizations then again models are trained, then the test set is predicted and scores are evaluated. We where not able to set a random state for this part, to accommodate this fact we saved the results via pickle so we can work on a consistent interpretation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_gridsearch_info_script(features, name):\n",
    "    rf_bf = dict()\n",
    "\n",
    "    param_grid = {\n",
    "        \"randomforestregressor__max_depth\": [2, 3, 5, 10, None],\n",
    "        \"randomforestregressor__min_samples_split\": [2, 3, 5, 10],\n",
    "        \"randomforestregressor__max_features\": [\"log2\", None]\n",
    "        }\n",
    "\n",
    "    df_score = pd.DataFrame(columns=['r2', 'rmse'], index=corr_cols)\n",
    "    for target in corr_cols:\n",
    "        if isinstance(features, dict):\n",
    "            rf_bf[target] = apply_gridsearch_rf(df, target, list(features[target]), param_grid, corr_cols, meta_cols, fprint=False)\n",
    "        else:\n",
    "            rf_bf[target] = apply_gridsearch_rf(df, target, features, param_grid, corr_cols, meta_cols, fprint=False)\n",
    "        df_score.loc[target,] = [rf_bf[target]['r2'] ,rf_bf[target]['rmse']]\n",
    "    \n",
    "    print('scores')\n",
    "    display(df_score)\n",
    "    \n",
    "    # file = os.path.join('pickle', name +'.obj')\n",
    "    # f = open(file, 'wb')\n",
    "    # pickle.dump(rf_bf ,f)\n",
    "    #f.close()    \n",
    "\n",
    "rf_bf = rf_gridsearch_info_script(selected_features_union, 'selected Features union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = open('pickle/rf_grid_selected_features_union.obj', 'rb')\n",
    "rf_bf = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "df_score = pd.DataFrame(columns=['r2', 'rmse'], index=corr_cols)\n",
    "for target in corr_cols:\n",
    "    df_score.loc[target,] = [rf_bf[target]['r2'] ,rf_bf[target]['rmse']]\n",
    "\n",
    "print('score: Grit Search Random Forrest selected Features union')\n",
    "display(df_score)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the scores table we can see, that after hyperparameter optimization the metrics of our model improved again a bit. An r2 of above 0.7 has been reached for 3 out of the four corruption indices and the rmse values seem reasonable as well in regards to the scale our corruption indices operate on. \n",
    "- ti_cpi: 0-100\n",
    "- bci_bci: 0-100\n",
    "- ti_cpm: 0-10\n",
    "- wbgi_cce: -2.5-2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_fi = [rf_bf[target]['feat_importance'] for target in corr_cols]\n",
    "df_fi = pd.concat(l_fi)\n",
    "\n",
    "df_fi = df_fi.reindex(df_fi.mean().sort_values(ascending=False).index, axis=1)\n",
    "col_names = df_fi.columns\n",
    "df_fi = df_fi.T.melt(\n",
    "    ignore_index=False,\n",
    "    value_vars = ['ti_cpi', 'bci_bci', 'ti_cpi_om', 'wbgi_cce'],\n",
    "    value_name = 'feature_importance'\n",
    ").reset_index().rename(columns={'index': 'feature', 'variable': 'corruption_index'})\n",
    "\n",
    "plt.rcdefaults()\n",
    "font = {'family' : 'normal',\n",
    "    'size'   : 14}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.barplot(df_fi, x='feature',  y='feature_importance', hue='corruption_index', palette='magma', width=0.6)\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.title('Feature importance')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature importance in the plot above we can see that the features have comparable levels of relevance to the different corruption indexes.\n",
    "The plot shows that our model sees  political and civil freedom aswell as live expectancy as good indicators for corruption levels. A full list of the most important features can be seen below.\n",
    "\n",
    "| code        | Description                 |\n",
    "| ----------------- | ------------------------------------------------ |\n",
    "| fh_pr_1.0         | Political Rights Rating                          |\n",
    "| fh_ipolity2       | Level of Democracy                               |\n",
    "| ihme_lifexp_0104t | Life Expectancy, Both sexes, Age 1-4 years       |\n",
    "| fh_cl_1.0         | Civil Liberties                                  |\n",
    "| ihme_lifexp_0104m | Life Expectancy, Male, Age 1-4 years             |\n",
    "| br_mon            | Is the country a monarchy                        |\n",
    "| cpds_vper_0.0     | Share of votes: personalist                      |\n",
    "| gd_ptss_1.0       | Political Terror Scale - US State Department     |\n",
    "| kun_cluster_5.0   | Cluster memberships based on means               |\n",
    "| wel_sys_1.0       | Political System Type                            |\n",
    "| cpds_lall_0.0     | Share of seats in parliament: electoral alliance |\n",
    "| fh_status_1.0     | Freedom Status                                   |\n",
    "| ciri_injud_2.0    | Independence of the Judiciary                    |\n",
    "| fhp_status5_1.0   | Freedom of the Press, Status (2001-2016)         |\n",
    "| wel_scalezone_4.0 | Scalezone on Citizen Rights                      |\n",
    "| cpds_chg_0.0      | Number of changes in government per year         |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dopp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "543aa23b88fc9de87e855576d5d47491130665cd749e56028ebe7cfa2e718f2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
